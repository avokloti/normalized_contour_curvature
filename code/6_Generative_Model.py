# -*- coding: utf-8 -*-
"""6. Generative Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GixU9zKxXltsjznhHCcNgdRZs8hCIOnz

# Generative Model

This notebook implements the generative model for constructing artificial images with NCC statistics matching a given distribution.

*Andrew Marantan, Irina Tolkova, and Lakshminarayanan Mahadevan (2020)*
"""

import numpy as np
import cv2
from google.colab.patches import cv2_imshow
import os
import pickle
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import pyplot as plt
from scipy.linalg import sqrtm

# mount Drive to access files
from google.colab import drive
drive.mount('/content/drive')

def contourCurvature(image, numBins, plot=False):
    # --- SETTINGS --- #
    
    # histogram bin edges
    kappaMin = -1;
    kappaMax = 1;
    dKappa = 2/numBins
    binEdges = np.linspace(kappaMin, kappaMax, numBins+1);

    bins = binEdges[0:-1] + dKappa/2;

    # --- Retrieve Image Properties --- #

    # obtain image dimensions #
    [numRows, numCols] = image.shape;
    imageLength = np.max((numRows, numCols));
    
    # set pixel spacing #
    dx = 1 / imageLength;

    # --- Calculate Contour Curvature --- #

    # shift image #
    f_N = np.roll(image, -1, 0);
    f_E = np.roll(image, -1, 1);
    f_S = np.roll(image, 1, 0);
    f_W = np.roll(image, 1, 1);

    f_NE = np.roll(np.roll(image, -1, 0), -1, 1)
    f_SE = np.roll(np.roll(image, 1, 0), -1, 1)
    f_SW = np.roll(np.roll(image, 1, 0), 1, 1)
    f_NW = np.roll(np.roll(image, -1, 0), 1, 1)

    # construct derivatives #
    f_x = (f_E - f_W)/(2 * dx);
    f_y = (f_N - f_S)/(2 * dx);
    f_xx = (f_E - 2*image + f_W)/(dx**2);
    f_yy = (f_N - 2*image + f_S)/(dx**2);
    f_xy = (f_NE - f_SE - f_NW + f_SW)/(4 * dx**2);

    # compute contour curvature #
    kappa = f_y**2 * f_xx + f_x**2 * f_yy - 2 * f_x * f_y * f_xy;
    kappa = kappa * (f_x**2 + f_y**2)**(-3/2);

    # convert to normalized curvature #
    kappa = -kappa / (2 + np.abs(kappa));

    # set flat patches to - dKappa #
    #kappa[np.isnan(kappa)] = -dKappa;

    # set background pixels to NaN #
    mask = np.isnan(image)
    kappa[mask] = np.nan

    # --- Calculate Histogram --- #

    # compute histogram for well-defined curavtures #
    kappaHist = np.histogram(np.ndarray.flatten(kappa), binEdges);
    print(kappaHist[0].shape)

    # include flat regions #
    #flatCounts = np.sum(np.ndarray.flatten(kappa) == -dKappa);

    #kappaHist = (np.insert(kappaHist[0], 0, flatCounts), np.insert(kappaHist[1], 0, -dKappa))

    # convert histogram to probability distribution #
    kappaDist = kappaHist[0] / np.sum( dKappa * kappaHist[0]);

    if (plot):
      plt.figure(figsize=(16, 5))

      plt.subplot(1, 2, 1)
      plt.pcolor(kappa)
      plt.gca().invert_yaxis()
      plt.colorbar()
      plt.title('Normalized Contour Curvature of Image');

      plt.subplot(1, 2, 2)
      plt.plot(bins, kappaDist)
      plt.title('Probability Density of NCC');
      plt.xlabel('Normalized Contour Curvature');
      plt.ylabel('Probability Density');

    return kappa, kappaDist, bins

def generatePatch(patch_X, patch_Y, bound_X, bound_Y, boundVals, xi):
    patchSize = patch_X.shape[0]
    
    numPatch = patch_X.shape[0] * patch_X.shape[1]
    numBound = bound_X.shape[0] * bound_X.shape[1]
    
    patch_X = np.reshape(patch_X, (numPatch, 1))
    patch_Y = np.reshape(patch_Y, (numPatch, 1))

    bound_X = np.reshape(bound_X, (numBound, 1))
    bound_Y = np.reshape(bound_Y, (numBound, 1))

    pos_X = np.concatenate((patch_X, bound_X));
    pos_Y = np.concatenate((patch_Y, bound_Y));

    # construct a distance matrix
    R2 = np.zeros((numPatch + numBound, numPatch + numBound));
    for ii in range(numPatch + numBound):
        for jj in range(numPatch + numBound):
            R2[ii, jj] = (pos_X[ii, 0] - pos_X[jj, 0])**2 + (pos_Y[ii, 0] - pos_Y[jj, 0])**2;
    
    # calculate covariance matrix and mean vector #
    Sigma = np.exp( - R2 / (2 * xi**2) );
    patchMean = np.zeros((numPatch, 1))
    
    if (numBound > 0):
        Sigma_pp = Sigma[0:numPatch, 0:numPatch];
        Sigma_pb = Sigma[0:numPatch, numPatch:];
        Sigma_bb = 10**(-4) * np.eye(numBound) +  Sigma[numPatch:, numPatch:];

        # calculate patch mean #
        lstsq_output = np.linalg.lstsq(Sigma_bb, boundVals);
        patchMean = Sigma_pb @ lstsq_output[0]

        # calculate conditional covariance matrix #
        lstsq_output = np.linalg.lstsq(Sigma_bb, Sigma_pb.T)
        Sigma = Sigma_pp - Sigma_pb @ lstsq_output[0];
    
    # calculate matrix square root #
    T = np.real(sqrtm(Sigma));

    # generate uncorrelated Gaussian rvs #
    rawGaussians = np.random.normal(0,  1, (T.shape[0], 1));

    # correlate variables #
    patch = np.transpose(T) @ rawGaussians + patchMean;
    patch = np.reshape(patch, (patchSize, patchSize))
    return patch

def drawXi(xiVec, xiCDF):
    # draw s1 and s2 in [0,1]
    s1 = np.random.rand()
    s2 = np.random.rand()
    
    # find xi bin
    xiIndex = np.nonzero(xiCDF > s1)[0][0]
    
    # draw xi from within bin
    return xiVec[xiIndex] + (s2 - 1/2) * (xiVec[1] - xiVec[0])

SAVEFIG = False

# make random input repeatable
np.random.seed(0)

stimuli_dir = '/content/drive/My Drive/Tolkova_Mahadevan/NCC Project/AnimacySize'

#xiVec = [0.00500000000000000,0.0100000000000000,0.0150000000000000,0.0200000000000000,0.0250000000000000,0.0300000000000000,0.0350000000000000,0.0400000000000000,0.0450000000000000,0.0500000000000000,0.0550000000000000,0.0600000000000000,0.0650000000000000,0.0700000000000000,0.0750000000000000,0.0800000000000000,0.0850000000000000,0.0900000000000000,0.0950000000000000,0.100000000000000,0.105000000000000,0.110000000000000,0.115000000000000,0.120000000000000,0.125000000000000,0.130000000000000,0.135000000000000,0.140000000000000,0.145000000000000,0.150000000000000,0.155000000000000,0.160000000000000,0.165000000000000,0.170000000000000,0.175000000000000,0.180000000000000,0.185000000000000,0.190000000000000,0.195000000000000,0.200000000000000,0.205000000000000,0.210000000000000,0.215000000000000,0.220000000000000,0.225000000000000,0.230000000000000,0.235000000000000,0.240000000000000,0.245000000000000,0.250000000000000,0.255000000000000,0.260000000000000,0.265000000000000,0.270000000000000,0.275000000000000,0.280000000000000,0.285000000000000,0.290000000000000,0.295000000000000,0.300000000000000,0.305000000000000,0.310000000000000,0.315000000000000,0.320000000000000,0.325000000000000,0.330000000000000,0.335000000000000,0.340000000000000,0.345000000000000,0.350000000000000,0.355000000000000,0.360000000000000,0.365000000000000,0.370000000000000,0.375000000000000,0.380000000000000,0.385000000000000,0.390000000000000,0.395000000000000,0.400000000000000,0.405000000000000,0.410000000000000,0.415000000000000,0.420000000000000,0.425000000000000,0.430000000000000,0.435000000000000,0.440000000000000,0.445000000000000,0.450000000000000,0.455000000000000,0.460000000000000,0.465000000000000,0.470000000000000,0.475000000000000,0.480000000000000,0.485000000000000,0.490000000000000,0.495000000000000,0.500000000000000,0.505000000000000,0.510000000000000,0.515000000000000,0.520000000000000,0.525000000000000,0.530000000000000,0.535000000000000,0.540000000000000,0.545000000000000,0.550000000000000,0.555000000000000,0.560000000000000,0.565000000000000,0.570000000000000,0.575000000000000,0.580000000000000,0.585000000000000,0.590000000000000,0.595000000000000,0.600000000000000,0.605000000000000,0.610000000000000,0.615000000000000,0.620000000000000,0.625000000000000,0.630000000000000,0.635000000000000,0.640000000000000,0.645000000000000,0.650000000000000,0.655000000000000,0.660000000000000,0.665000000000000,0.670000000000000,0.675000000000000,0.680000000000000,0.685000000000000,0.690000000000000,0.695000000000000,0.700000000000000,0.705000000000000,0.710000000000000,0.715000000000000,0.720000000000000,0.725000000000000,0.730000000000000,0.735000000000000,0.740000000000000,0.745000000000000,0.750000000000000,0.755000000000000,0.760000000000000,0.765000000000000,0.770000000000000,0.775000000000000,0.780000000000000,0.785000000000000,0.790000000000000,0.795000000000000,0.800000000000000,0.805000000000000,0.810000000000000,0.815000000000000,0.820000000000000,0.825000000000000,0.830000000000000,0.835000000000000,0.840000000000000,0.845000000000000,0.850000000000000,0.855000000000000,0.860000000000000,0.865000000000000,0.870000000000000,0.875000000000000,0.880000000000000,0.885000000000000,0.890000000000000,0.895000000000000,0.900000000000000,0.905000000000000,0.910000000000000,0.915000000000000,0.920000000000000,0.925000000000000,0.930000000000000,0.935000000000000,0.940000000000000,0.945000000000000,0.950000000000000,0.955000000000000,0.960000000000000,0.965000000000000,0.970000000000000,0.975000000000000,0.980000000000000,0.985000000000000,0.990000000000000,0.995000000000000,1];
#xiDist = [1.82464554426181e-05,3.51703210711365e-05,6.83668503446064e-05,0.000137476321778336,0.000300882285639831,0.000778820115755864,0.00290985933881817,0.0435553115501528,0.0337550915355891,0.00535244003559669,0.00255909269503798,0.00171204937658248,0.00135433199395534,0.00118647196823316,0.00111400226353469,0.00110142312229651,0.00113438058746679,0.00120885230736482,0.00132714981885938,0.00149741328182672,0.00173468857695255,0.00206239457597092,0.00252064132807587,0.00317230911384978,0.00413036453905354,0.00559113390987798,0.00794020658795022,0.0119959113709670,0.0196380493393804,0.0357676800854419,0.0730501963611072,0.138962572032276,0.136173886872319,0.0764055837898329,0.0425256511294374,0.0265825992236550,0.0183670210655704,0.0136744162132278,0.0107657540487497,0.00884882323212148,0.00752375546255200,0.00657924007574568,0.00588276542371051,0.00536419717214551,0.00498175752335142,0.00467927208210709,0.00446941329496707,0.00430719219723653,0.00420139073482421,0.00413770236159000,0.00411040646076541,0.00411944782218060,0.00415912030170085,0.00422967579033880,0.00433359258139394,0.00446707964010366,0.00462673467932027,0.00483051947212140,0.00505281720873628,0.00531674347761653,0.00560242426978609,0.00592476477626540,0.00625181614309560,0.00660253281243089,0.00693808182982237,0.00724195353552214,0.00748804385990470,0.00765736125098337,0.00770860225472613,0.00763084574608152,0.00742996546370095,0.00709624906064909,0.00666894779600954,0.00618137786436064,0.00564523443637079,0.00511393697257752,0.00459798803229872,0.00411996724939211,0.00367519192050120,0.00327721599528336,0.00292268596200111,0.00260992961071632,0.00233398141965247,0.00209241601266849,0.00188059914056343,0.00169519176889271,0.00153248139876964,0.00138952972862766,0.00126375740469196,0.00115261596855250,0.00105447043478952,0.000967274551151077,0.000889700935407431,0.000820491990067307,0.000758618596853317,0.000703126563223083,0.000653163928263407,0.000608086286671827,0.000567415814413558,0.000530502216379111,0.000496983374907739,0.000466450129835577,0.000438571126448440,0.000413071782426457,0.000389694939746514,0.000368228913171622,0.000348471595481195,0.000330255776503850,0.000313429762263878,0.000297860251229142,0.000283429312702487,0.000270032726217830,0.000257575271156475,0.000245974542854349,0.000235156601666752,0.000225053032012586,0.000215604619009900,0.000206756872993071,0.000198461347589385,0.000190674049496393,0.000183354758626156,0.000176467918559875,0.000169980472821940,0.000163862890465233,0.000158087943835339,0.000152630815864803,0.000147469164480627,0.000142582213661774,0.000137951078166984,0.000133558513140631,0.000129388450256282,0.000125426595800845,0.000121659039325285,0.000118073886093713,0.000114659204575224,0.000111404594309674,0.000108300482423145,0.000105337533731172,0.000102507441801367,9.98024765665381e-05,9.72153140551737e-05,9.47394243057086e-05,9.23683200077795e-05,9.00962926355447e-05,8.79179262367856e-05,8.58280836793444e-05,8.38220594671612e-05,8.18954567797579e-05,8.00441368195705e-05,7.82642061855983e-05,7.65520133336027e-05,7.49041675781114e-05,7.33175034173840e-05,7.17890474611740e-05,7.03158907500359e-05,6.88954406369026e-05,6.75251649057731e-05,6.62027246772308e-05,6.49259185102354e-05,6.36927025045242e-05,6.25010072111106e-05,6.13490423421773e-05,6.02350102158349e-05,5.91572681088512e-05,5.81142149388498e-05,5.71044207219298e-05,5.61264052205319e-05,5.51788502490362e-05,5.42605314693184e-05,5.33702255363159e-05,5.25067927623951e-05,5.16691087549256e-05,5.08561772563117e-05,5.00670173083544e-05,4.93007071523814e-05,4.85563485930098e-05,4.78331228192726e-05,4.71301799796141e-05,4.64467927423736e-05,4.57822233091870e-05,4.51357688646340e-05,4.45067671210499e-05,4.38946006896639e-05,4.32986349880476e-05,4.27183106880044e-05,4.21530804811168e-05,4.16023827633927e-05,4.10657783127124e-05,4.05427293607157e-05,4.00327738331480e-05,3.95355005865314e-05,3.90504521598305e-05,3.85772520905333e-05,3.81154789972832e-05,3.76647738478620e-05,3.72247975053252e-05,3.67951820659243e-05,3.63755926002178e-05,3.59657266331394e-05,3.55652877618077e-05];

# read in animate distribution
with open(stimuli_dir + '/model_xi_distribution_aug15', 'rb') as pickle_file:
    xiDist = pickle.load(pickle_file)

with open(stimuli_dir + '/model_ncc_distribution_aug15', 'rb') as pickle_file:
    nccDist = pickle.load(pickle_file)

xiVec = np.arange(0.005, 2.001, step=0.005)
xiCDF = np.cumsum(xiDist);

plt.figure(figsize=(6, 4))
plt.plot(xiVec[0:200], xiDist[0:200]/(xiVec[2] - xiVec[1]))
plt.title('Correlation Length Distribution for Generative Model', fontsize=16)
plt.xlabel(r'Scaled Correlation Length $\xi$', fontsize=14)
plt.ylabel(r'Probability Density $P(\xi)$', fontsize=14)

SAVEFIG = 1
if (SAVEFIG):
    plt.savefig('/content/drive/My Drive/Tolkova_Mahadevan/NCC Project/Figures/fig_6a.pdf')

def generateImage(xiVec, xiDist, imageSize, patchSize):
  xiCDF = np.cumsum(xiDist)

  # extract image size parameters (IT: assumes square image)
  numRows = imageSize[0] - np.mod(imageSize[0], patchSize);
  numCols = imageSize[1] - np.mod(imageSize[1], patchSize);

  # boundary setting
  boundOffset = patchSize;

  # instantiate image with all NaNs
  image = np.empty((numRows, numCols))
  image[:] = np.nan;

  # instantiate position arrays
  xVec = (np.arange(numCols) - 1/2 * np.ones(numCols)) / numCols;
  yVec = (np.arange(numRows) - 1/2 * np.ones(numRows)) / numCols;
  [X, Y] = np.meshgrid(xVec, yVec);

  for ii in range(numRows // patchSize):
      for jj in range(numCols // patchSize):
          # obtain correlation length
          xi = drawXi(xiVec, xiCDF);

          # extract patch coordinates
          # X and Y indices #
          minRow = ii * patchSize;
          maxRow = (ii+1) * patchSize;
          minCol = jj * patchSize;
          maxCol = (jj + 1) * patchSize;

          # patch pixel positions #
          patch_X = X[minRow:maxRow, minCol:maxCol];
          patch_Y = Y[minRow:maxRow, minCol:maxCol];

          # extract boundary information #
          # initialize boundary arrays #
          bound_W_X = [];
          bound_W_Y = [];
          bound_W_Vals = [];

          bound_N_X = [];
          bound_N_Y = [];
          bound_N_Vals = [];

          # extract northern boundary properties #
          if (ii > 0):
              bound_N_rows_min = np.max((0, minRow - boundOffset))
              bound_N_rows_max = minRow
              bound_N_cols_min = np.max((0, minCol-boundOffset))
              bound_N_cols_max = np.min((maxCol+boundOffset, numCols))

              bound_N_rows = np.arange(bound_N_rows_min, bound_N_rows_max);
              bound_N_cols = np.arange(bound_N_cols_min, bound_N_cols_max);

              bound_N_X = X[bound_N_rows_min:bound_N_rows_max, bound_N_cols_min:bound_N_cols_max];
              bound_N_Y = Y[bound_N_rows_min:bound_N_rows_max, bound_N_cols_min:bound_N_cols_max];
              bound_N_Vals = image[bound_N_rows_min:bound_N_rows_max, bound_N_cols_min:bound_N_cols_max];
          
          # extract western boundary properties #
          if (jj > 0):
              #print("ii = " + str(ii) + "  jj = " + str(jj))
              bound_W_rows_min = minRow
              bound_W_rows_max = maxRow
              bound_W_cols_min = np.max((0, minCol - boundOffset))
              bound_W_cols_max = minCol

              bound_W_rows = np.arange(bound_W_rows_min, bound_W_rows_max);
              bound_W_cols = np.arange(bound_W_cols_min, bound_W_cols_max);

              bound_W_X = X[bound_W_rows_min:bound_W_rows_max, bound_W_cols_min:bound_W_cols_max];
              bound_W_Y = Y[bound_W_rows_min:bound_W_rows_max, bound_W_cols_min:bound_W_cols_max];
              bound_W_Vals = image[bound_W_rows_min:bound_W_rows_max, bound_W_cols_min:bound_W_cols_max];
          
          # set boundary arrays
          bound_W_X_size = 0
          bound_W_Y_size = 0
          bound_N_X_size = 0
          bound_N_Y_size = 0
          bound_W_Vals_size = 0
          bound_N_Vals_size = 0

          if (len(bound_W_X) != 0):
              #print(np.size(bound_W_X))
              bound_W_X_size = bound_W_X.size
          if (len(bound_W_Y) != 0):
              bound_W_Y_size = bound_W_Y.size
          if (len(bound_N_X) != 0):
              bound_N_X_size = bound_N_X.size
          if (len(bound_N_Y) != 0):
              bound_N_Y_size = bound_N_Y.size
          if (len(bound_W_Vals) != 0):
              bound_W_Vals_size = bound_W_Vals.size
          if (len(bound_N_Vals) != 0):
              bound_N_Vals_size = bound_N_Vals.size
          
          bound_X = np.concatenate((np.reshape(bound_W_X, (bound_W_X_size, 1)), np.reshape(bound_N_X, (bound_N_X_size, 1))));
          bound_Y = np.concatenate((np.reshape(bound_W_Y, (bound_W_Y_size, 1)), np.reshape(bound_N_Y, (bound_N_Y_size, 1))));
          boundVals = np.concatenate((np.reshape(bound_W_Vals, (bound_W_Vals_size, 1)), np.reshape(bound_N_Vals, (bound_N_Vals_size, 1))));
          
          # generate patch given boundary values #
          patch = generatePatch(patch_X, patch_Y, bound_X, bound_Y, boundVals, xi);

          # add patch to image #
          image[minRow:maxRow, minCol:maxCol] = patch;
  
  return image

## --- Test Generator --- ##

# flag to indicate whether images should be generated or loaded
CALCULATE = True

# set image size
imageSize = (50, 50)
# set patch size
patchSize = 25
# set number of images
numImages = 100

# curvature settings #
numBins = 101
dKappa = 2/numBins
kappaBinEdges = np.linspace(-1, 1, numBins+1);
kappaBins = kappaBinEdges[0:-1] + dKappa/2;

if (CALCULATE):
    # initialize data arrays
    images = []
    cutImages = []
    kappaImages = []
    kappaHists = np.zeros((numImages, numBins))

    # generate images #
    for n in range(numImages):
        image = generateImage(xiVec, xiDist, imageSize, patchSize)
        images.append(image)
        if (np.mod(n+1, 5) == 0):
            print('Generated image %d/%d!' % (n+1, numImages))
    
    # process images #
    for n in range(numImages):
        # load image #
        image = images[n]
        
        # cut off values below threshold #
        cutImage = image #filteredImage;
        cutImage[image < -3] = np.nan
        
        # calculate NCC image and histogram #
        kappaImage, kappaHist, bins = contourCurvature(cutImage, numBins)
        
        # store data #
        cutImages.append(cutImage)
        kappaImages.append(kappaImage);
        kappaHists[n,:] = kappaHist;

        if (np.mod(n+1, 5) == 0):
            print('Processed image %d/%d!' % (n+1, numImages))
    
    # save images and histograms
    with open(stimuli_dir + '/generative_model_images_%dx%d_p%d_aug15' % (imageSize[0], imageSize[1], patchSize), 'wb') as pickle_file:
        pickle.dump(images, pickle_file)

    # save histograms
    with open(stimuli_dir + '/generative_model_histograms_%dx%d_p%d_aug15' % (imageSize[0], imageSize[1], patchSize), 'wb') as pickle_file:
        pickle.dump(kappaHists, pickle_file)
    
else:
    # save images and histograms
    with open(stimuli_dir + '/generative_model_images_%dx%d_p%d_aug15' % (imageSize[0], imageSize[1], patchSize), 'rb') as pickle_file:
        images = pickle.load(pickle_file)
    
    cutImages = []
    kappaImages = []
    kappaHists = np.zeros((numImages, numBins))
    
    for n in range(numImages):
        # load image #
        image = images[n]
        
        # cut off values below threshold #
        cutImage = image #filteredImage;
        cutImage[image < -3 * np.std(image)] = np.nan
        
        # calculate NCC image and histogram #
        kappaImage, kappaHist, bins = contourCurvature(cutImage, numBins)
        
        # store data #
        #cutImages.append(cutImage)
        kappaImages.append(kappaImage);
        kappaHists[n,:] = kappaHist;

        if (np.mod(n+1, 5) == 0):
            print('Processed image %d/%d!' % (n+1, numImages))

    # save histograms
    #with open(stimuli_dir + '/generative_model_histograms_50x50', 'rb') as pickle_file:
        #kappaHists = pickle.load(pickle_file)

# load true animate distribution
with open(stimuli_dir + '/animate_mean_aug15', 'rb') as pickle_file:
    animateDist = pickle.load(pickle_file)

# load theoretical distribution (corresponding to xi)
with open(stimuli_dir + '/model_ncc_distribution_aug15', 'rb') as pickle_file:
    theoreticalDist = pickle.load(pickle_file)

SAVEFIG = False

# calculate average and standard deviation of distribution
histMean = np.mean(kappaHists, axis=0)
histStd = np.std(kappaHists, axis=0)

# plot distribution
fig, ax = plt.subplots(1, 1)
fig.set_size_inches(6, 4)

l1, = ax.plot(kappaBins, histMean, linewidth=2)
#ax.fill_between(bins, np.squeeze(histMean) - np.squeeze(histStd), np.squeeze(histMean) + np.squeeze(histStd), alpha=0.5, color='C2')
ax.set_xlabel(r'Normalized Contour Curvature $\hat{\kappa}$', fontsize=14)
ax.set_ylabel(r'Probability Density $P(\hat{\kappa})$', fontsize=14)
#ax.set_title('Generated NCC: Image Size (%d, %d), Patch Size %d' % (imageSize[0], imageSize[1], patchSize), fontsize=16)
ax.set_title('Validation of NCC Statistics of Generative Model', fontsize=16)

l2, = ax.plot(kappaBins, theoreticalDist, linewidth=2)
l3, = ax.plot(kappaBins, animateDist/(dKappa * np.sum(animateDist)), linewidth=2)
ax.legend([l1, l2, l3], ['Generated Images', 'Theoretical Distribution', 'True Animate Distribution'], fontsize=14)

ax.plot()

if (0):
    plt.savefig('/content/drive/My Drive/Tolkova_Mahadevan/NCC Project/Figures/fig_6b.pdf')

images[0][20, 20]

# generate images #
plt.figure(figsize=(6, 4))
fig, axs = plt.subplots(2, 3)
for n in range(6):
    plt.subplot(2, 3, n+1)
    image_plot = np.nan_to_num(images[n], copy=True, nan=np.nanmin(images[n]))
    #plt.pcolor(images[n]/np.nanstd(images[n]), cmap='gray')
    plt.pcolor(image_plot, cmap='gray_r')
    axs[n // 3, np.mod(n, 3)].set_aspect('equal', 'box')
    plt.axis('off')
    #plt.colorbar()

if (0):
    plt.savefig('/content/drive/My Drive/Tolkova_Mahadevan/NCC Project/Figures/fig_s6_bottom.pdf')

## --- Test Generator --- ##

# flag to indicate whether images should be generated or loaded
CALCULATE = True

# set image size
imageSize = (50, 50)
# set patch size
patchSize = 5
# set number of images
numImages = 100

# curvature settings #
numBins = 101
dKappa = 2/numBins
kappaBinEdges = np.linspace(-1, 1, numBins+1);
kappaBins = kappaBinEdges[0:-1] + dKappa/2;

#xi_vec = np.arange(0.005, 2.001, step=0.005)

# load means of distribution for all four groups
category_filenames = {'Large Animate': 'big_animate_mean_ncc',
                      'Small Animate': 'small_animate_mean_ncc',
                      'Large Inanimate': 'big_inanimate_mean_ncc',
                      'Small Inanimate': 'small_inanimate_mean_ncc'}

stimuli_dir = '/content/drive/My Drive/Tolkova_Mahadevan/NCC Project/AnimacySize'


# load in:
group_means = {}
xi_dists = {}
for cat in category_filenames.keys():
    with open(stimuli_dir + '/' + category_filenames[cat] + '.pickle', 'rb') as pickle_file:
        group_mean = pickle.load(pickle_file)

    with open(stimuli_dir + '/xi_dist_' + category_filenames[cat] + '_v2.pickle', 'rb') as pickle_file:
        xi_dists[cat] = pickle.load(pickle_file)

with open(stimuli_dir + '/xi_vec_v2.pickle', 'rb') as pickle_file:
    xi_vec = pickle.load(pickle_file)


# initialize data arrays
images = {}
cutImages = {}
kappaImages = {}
kappaHists = {}

# for each category, solve for distribution and plot
for cat in category_filenames.keys():
    # generate images #
    images[cat] = generateImage(xi_vec, xi_dists[cat][0], imageSize, patchSize)

    # cut off values below threshold #
    #print(np.std(images[cat]))
    images[cat] = images[cat]/np.std(images[cat])
    cutImage = images[cat]
    #print(np.std(cutImage))
    cutImage[images[cat] < -1] = np.nan
    
    # calculate NCC image and histogram #
    kappaImage, kappaHist, bins = contourCurvature(cutImage, numBins)
    
    # store data #
    cutImages[cat] = cutImage
    kappaImages[cat] = kappaImage
    kappaHists[cat] = kappaHist

plt.figure()
i = 1
for cat in category_filenames.keys():
    plt.subplot(2, 2, i)
    plt.plot(xi_vec, xi_dists[cat][0])
    plt.title(cat)
    i += 1

# generate images #
fig, axs = plt.subplots(4, 3, figsize=(8, 11))
n = 0
for cat in category_filenames.keys():
    plt.subplot(4, 3, 3 * n + 1)
    image_plot = np.nan_to_num(images[cat], copy=True, nan=np.nanmin(images[cat]))
    image_plot = image_plot/np.nanstd(images[cat])
    #plt.pcolor(images[n]/np.nanstd(images[n]), cmap='gray')
    pcol = plt.pcolor(image_plot, cmap='gray_r', linewidth=0, rasterized=True)
    pcol.set_edgecolor('face')
    axs[n, 0].set_aspect('equal', 'box')
    plt.axis('off')
    #plt.colorbar()
    if (n == 0):
        plt.title('Generated Image', fontsize=16)
    #plt.ylabel(cat, fontsize=16)
    #axs[n, 0].set_yticklabels([])
    #axs[n, 0].set_yticks([])
    #axs[n, 0].set_xticklabels([])
    #axs[n, 0].set_xticks([])
    plt.axis('equal')

    plt.subplot(4, 3, 3 * n + 2)
    plt.contour(image_plot)
    #plt.gca().invert_yaxis()
    plt.axis('off')
    if (n == 0):
        plt.title('Contour Plot', fontsize=16)
    plt.axis('equal')

    plt.subplot(4, 3, 3 * n + 3)
    plt.pcolor(kappaImages[cat])
    axs[n, 1].set_aspect('equal')
    plt.axis('off')
    plt.axis('equal')
    #plt.colorbar()
    if (n == 0):
        plt.title('NCC Image', fontsize=16)

    #plt.subplot(4, 4, 4 * n + 4)
    #plt.plot(bins, kappaHists[cat])
    #if (n == 0):
    #    plt.title('NCC Histogram', fontsize=16)
    
    #plt.ylabel(r'$P(\hat{\kappa})$', fontsize=14)
    #plt.xlabel(r'$\hat{\kappa}$', fontsize=14)
    #plt.colorbar()
    n += 1

plt.tight_layout()
#plt.savefig('/content/drive/My Drive/Tolkova_Mahadevan/NCC Project/Figures/\
#  generative_examples_p%d_part1_v2.pdf' % patchSize, dpi=400)

fig, axs = plt.subplots(4, 1, figsize=(4, 11))

n = 0
for cat in category_filenames.keys():
    plt.subplot(4, 1, n + 1)
    plt.plot(bins, kappaHists[cat])
    if (n == 0):
        plt.title('NCC Distribution', fontsize=16)
    
    plt.ylabel(r'Probability Density $P(\hat{\kappa})$', fontsize=14)
    plt.xlabel(r'Normalized Contour Curvature $\hat{\kappa}$', fontsize=14)
    #plt.colorbar()
    n += 1

plt.tight_layout()
#plt.savefig('/content/drive/My Drive/Tolkova_Mahadevan/NCC Project/Figures/\
#  generative_examples_p%d_part2_v2.pdf' % patchSize, dpi=400)

# Make a figure with generated images for different patch size, single class
patch_sizes = [3, 5, 10, 25]

images = {}
for i in range(len(patch_sizes)):
    images[patch_sizes[i]] = []
    for j in range(3):
        # generate images #
        image = generateImage(xi_vec, xi_dists['Large Animate'][0], imageSize, patch_sizes[i])

        # cut off values below threshold #
        image = image/np.std(image)
        cutImage = image
        cutImage[image < -1] = np.nan
        
        # calculate NCC image and histogram #
        kappaImage, kappaHist, bins = contourCurvature(cutImage, numBins)

        image_plot = np.nan_to_num(image, copy=True, nan=np.nanmin(image))
        image_plot = image_plot/np.nanstd(image)
        images[patch_sizes[i]].append(image_plot)

plt.figure(figsize=(15, 9))
for i in range(4):
    for j in range(3):
        plt.subplot(3, 4, 4 * j + i + 1)
        plt.pcolor(images[patch_sizes[i]][j], cmap='gray_r', linewidth=0, rasterized=True)
        axs[i].set_aspect('equal', 'box')
        plt.axis('off')
        plt.axis('equal')
        #plt.colorbar()
        if (j == 0):
          plt.title('Generated Examples \n Scaled Patch Size = %.2f' % (patch_sizes[i]/imageSize[0]), fontsize=14)

plt.tight_layout()
plt.savefig('/content/drive/My Drive/Tolkova_Mahadevan/NCC Project/Figures/\
  generative_examples_across_patch_size.pdf', dpi=400)

# generate images #
fig, axs = plt.subplots(4, 2, figsize=(20, 16))
for n in range(4):
    plt.subplot(4, 4, 4 * n + 1)
    image_plot = np.nan_to_num(images[n], copy=True, nan=np.nanmin(images[n]))
    image_plot = image_plot/np.nanstd(images[n])
    #plt.pcolor(images[n]/np.nanstd(images[n]), cmap='gray')
    plt.pcolor(image_plot, cmap='gray_r')
    axs[n, 0].set_aspect('equal', 'box')
    plt.axis('off')
    plt.axis('equal')
    plt.colorbar()
    plt.title('Generated Image')

    plt.subplot(4, 4, 4 * n + 2)
    plt.contour(image_plot)
    #plt.gca().invert_yaxis()
    plt.axis('off')
    plt.title('Contour Plot')
    plt.axis('equal')

    plt.subplot(4, 4, 4 * n + 3)
    plt.pcolor(kappaImages[n])
    axs[n, 1].set_aspect('equal')
    plt.axis('off')
    plt.axis('equal')
    plt.colorbar()
    plt.title('NCC Image')

    plt.subplot(4, 4, 4 * n + 4)
    plt.plot(bins, kappaHists[n,:])
    plt.title('NCC Histogram')
    #plt.colorbar()

plt.tight_layout()


if (1):
    plt.savefig('/content/drive/My Drive/Tolkova_Mahadevan/NCC Project/Figures/\
    generative_examples_%dx%d_p%d_aug15.png' % (imageSize[0], imageSize[1], patchSize))

# set image size
imageSize = (50, 50)
# set patch size
patchSize = 3
# set number of images
numImages = 3

# generate images #
fig, axs = plt.subplots(1, 3, figsize=(12, 4))
for n in range(3):
    image = generateImage(xiVec, xiDist, imageSize, patchSize)
    
    # cut off values below threshold #
    image = image/np.std(image)
    cutImage = image
    cutImage[image < -1] = np.nan

    image_plot = np.nan_to_num(cutImage, copy=True, nan=np.nanmin(cutImage))

    plt.subplot(1, 3, n+1)
    plt.pcolor(image_plot, cmap='gray_r', linewidth=0, rasterized=True)
    axs[n].set_aspect('equal', 'box')
    plt.axis('off')
    plt.axis('equal')

plt.tight_layout()
plt.savefig('/content/drive/My Drive/Tolkova_Mahadevan/NCC Project/Figures/fig_6b.pdf')

"""
for n in range(numImages):
    # load image #
    image = images[n]
    
    # cut off values below threshold #
    cutImage = image #filteredImage;
    cutImage[image < -3] = np.nan
    
    # calculate NCC image and histogram #
    kappaImage, kappaHist, bins = contourCurvature(cutImage, numBins)
    
    # store data #
    cutImages.append(cutImage)
    kappaImages.append(kappaImage);
    kappaHists[n,:] = kappaHist;


# calculate average and standard deviation of distribution
histMean = np.mean(kappaHists, axis=0)
histStd = np.std(kappaHists, axis=0)"""